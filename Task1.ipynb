{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da73f216",
   "metadata": {},
   "source": [
    "#### 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e616e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8daeac4",
   "metadata": {},
   "source": [
    "#### Method 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ca13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunking(documents_df_, chunk_size_, chunk_overlap_):\n",
    "    \"\"\"\n",
    "    chunk_size_, chunk_overlap_에 따라, documents_df_의 텍스트를 Chunking\n",
    "    \"\"\"\n",
    "    chunk_results = []\n",
    "    chunk_idx = 0\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size_,\n",
    "        chunk_overlap=chunk_overlap_,\n",
    "        length_function=len\n",
    "    )\n",
    "\n",
    "    for idx, row in documents_df_.iterrows():\n",
    "        origin_text = row['summary']\n",
    "\n",
    "        chunks = text_splitter.create_documents([origin_text])\n",
    "\n",
    "        for chunk in chunks:\n",
    "            chunk_results.append({\n",
    "                'chunk_id':chunk_idx,\n",
    "                'text':chunk.page_content,\n",
    "                'metadata':{\n",
    "                    'category':row['category'],\n",
    "                    'press':row['press'],\n",
    "                    'title':row['title'],\n",
    "                    'chunk_size':len(chunk.page_content)\n",
    "                }\n",
    "            })\n",
    "            chunk_idx += 1\n",
    "\n",
    "    return chunk_results\n",
    "\n",
    "def retrieval(embedding_model_name: str, collection_name: str, query: str, top_k: int, use_instruct_prefix=False):\n",
    "    \"\"\"\n",
    "    Query를 임베딩하고, Qdrant 컬렉션에서 관련 문서를 검색.\n",
    "    \"\"\"\n",
    "\n",
    "    # 임베딩 모델 로드\n",
    "    embedding_model = SentenceTransformer(embedding_model_name)\n",
    "\n",
    "    # 쿼리 임베딩\n",
    "    if use_instruct_prefix: # Instruct 모델을 사용하는 경우 'query: ' 접두사 추가\n",
    "        query = f\"query: {query}\"\n",
    "\n",
    "    query_vector = embedding_model.encode(query).tolist()\n",
    "\n",
    "    # Qdrant Client 로드\n",
    "    client = QdrantClient(host='localhost', port=6333)\n",
    "\n",
    "    # Qdrant 검색 수행\n",
    "    search_results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_vector,\n",
    "        limit=top_k,\n",
    "        with_payload=True, # 검색된 포인트의 메타 데이터\n",
    "        with_vectors=False # 검색된 포인트의 임베딩 벡터 (필요 X)\n",
    "    )\n",
    "\n",
    "    # 결과 출력\n",
    "    if not search_results:\n",
    "        print(f\"ERROR: 검색 결과가 없습니다.\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    for rank, result in enumerate(search_results):\n",
    "        payload = result.payload\n",
    "\n",
    "        chunk_text = payload.get('text', '텍스트 없음')\n",
    "        source_title = payload.get('title', '제목 없음')\n",
    "        source_press = payload.get('press', '출처 없음')\n",
    "\n",
    "        print(f\"[{rank}]: \\nchunk_text: {chunk_text}\\nsource_title: {source_title}\\nsource_press: {source_press}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e794d",
   "metadata": {},
   "source": [
    "#### 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2ba682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "dataset_id = 'daekeun-ml/naver-news-summarization-ko'\n",
    "dataset = load_dataset(dataset_id, split='test')\n",
    "documents_df = dataset.to_pandas()\n",
    "\n",
    "# # Example\n",
    "# print(f\"문서 수 : {len(documents_df)}\")\n",
    "# print(f\"문서 Columns : {documents_df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a4bcec",
   "metadata": {},
   "source": [
    "#### CHUNKING -> EMBEDDING -> INDEXING\n",
    "* Chunk Size, Chunk Overlap, Embedding Model, Collection Name 확인 필수!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256a5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta-multitask. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24530826b89b48c5b60503f155f682b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1755 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 변수 설정\n",
    "CHUNK_SIZE, CHUNK_OVERLAP = 180, 36\n",
    "EMBEDDING_MODEL_NAME = \"BM-K/KoSimCSE-roberta-multitask\"\n",
    "COLLECTION_NAME = ''\n",
    "USE_INSTRUCT_PREFIX = False\n",
    "\n",
    "# Chunking\n",
    "chunk_results = chunking(documents_df, CHUNK_SIZE, CHUNK_OVERLAP)\n",
    "\n",
    "# Retriever 모델 선택 및 임베딩\n",
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "\n",
    "EMBEDDING_DIM = embedding_model.get_sentence_embedding_dimension() # 임베딩 차원 확인\n",
    "\n",
    "chunk_texts = [chunk['text'] for chunk in chunk_results] # 청크 텍스트 리스트\n",
    "\n",
    "if USE_INSTRUCT_PREFIX:\n",
    "    chunk_texts = [f\"passage: {chunk_text}\" for chunk_text in chunk_texts]\n",
    "\n",
    "embeddings = embedding_model.encode(chunk_texts, show_progress_bar=True) # 임베딩 / 임베딩 과정 시각화\n",
    "\n",
    "# Qdrant 컬렉션 구축\n",
    "client = QdrantClient(host='localhost', port=6333)\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIM,\n",
    "        distance=models.Distance.COSINE # 코사인 유사도\n",
    "    )\n",
    ")\n",
    "\n",
    "# Indexing: Qdrant에 포인트 삽입\n",
    "points = []\n",
    "\n",
    "# Qdrant에 삽입할 PointStruct 리스트 생성\n",
    "for idx, chunk in enumerate(chunk_results):\n",
    "    # metadata를 Payload로 사용, 원문 'text'를 포함\n",
    "    payload_data = chunk['metadata']\n",
    "    payload_data['text'] = chunk['text']\n",
    "\n",
    "    # PointStruct 생성: id는 chunk_id(0부터 시작) 사용\n",
    "    points.append(\n",
    "        models.PointStruct(\n",
    "            id=chunk['chunk_id'], # 청크 ID를 Qdrant의 고유 ID로 사용\n",
    "            vector=embeddings[idx].tolist(), # numpy 배열을 list로 변환하여 삽입\n",
    "            payload=payload_data\n",
    "        )\n",
    "    )\n",
    "\n",
    "# 데이터 삽입(upsert)\n",
    "operation_info = client.upsert(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    wait=True, # 작업 완료 대기\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a8e774",
   "metadata": {},
   "source": [
    "#### Retrieval: Query -> Top K개의 Chunk 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME = \"BM-K/KoSimCSE-roberta-multitask\"\n",
    "COLLECTION_NAME = ''\n",
    "QUERY = ''\n",
    "TOP_K = 3\n",
    "\n",
    "retrieval(EMBEDDING_MODEL_NAME, COLLECTION_NAME, QUERY, TOP_K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
